{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63bdbe84",
   "metadata": {},
   "source": [
    "# Data Importer\n",
    "[![Static Badge](https://img.shields.io/badge/Jupyter_Notebook-F37726?style=for-the-badge)](https://jupyter.org/)\n",
    "\n",
    "<br>\n",
    "\n",
    "Performs any **adhoc** database operations that need to be done in bulk. \n",
    "\n",
    "<br>\n",
    "\n",
    "## Requirements\n",
    "- Python (Version 3.6 or up)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## Installation\n",
    "Run the pip install command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47394d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d5b6c5",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Initialization\n",
    "\n",
    "Run the codeblock below to initialize all the necessary tools\n",
    "\n",
    "<br>\n",
    "\n",
    "> ***‚ùáÔ∏è Important*** <br>\n",
    ">\n",
    "> You may need to restart the kernel of this notebook if you changed anything in the source code\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4763c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(1, r\"src\")\n",
    "\n",
    "import DataImporter as DI\n",
    "\n",
    "        \n",
    "########\n",
    "# MAIN #\n",
    "########\n",
    "Secrets = DI.DBSecrets.load()\n",
    "Database = DI.DBNames.Prod.value\n",
    "importer = DI.Importer(Secrets, database = Database, useConnPool = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27adcaa2",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Dataset Format\n",
    "A *dataset* is a folder that contains many .csv files.<br> \n",
    "For simplicity, each .csv file references a particular table. \n",
    "\n",
    "<br>\n",
    "\n",
    "> ***üìù NOTE:*** <br>\n",
    ">\n",
    "> The id keys in the .csv files are only for convenience of debugging\n",
    "> \n",
    "> These ids will be regenerated on the database side.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## Importing a Dataset\n",
    "\n",
    "The following codeblock gives some example of importing a dataset. <br>\n",
    "The data will first be cleaning, before being imported.\n",
    "\n",
    "<br>\n",
    "\n",
    "For cleaning, we have the following settings:\n",
    "\n",
    "| Clean Level | Description |\n",
    "| ----------- | ----------- |\n",
    "| None        | No data cleaning done |\n",
    "| Tuples      | Clears all data from every table |\n",
    "| Tables      | Deletes every table in the database |\n",
    "| Database    | Deletes an entire database |\n",
    "\n",
    "<br>\n",
    "\n",
    "For importing, we have the following setttings:\n",
    "\n",
    "| Build Level | Description |\n",
    "| ----------- | ----------- |\n",
    "| Tuples      | Only Imports the data into existing tables |\n",
    "| Tables      | Constructs the required tables, then imports the data |\n",
    "| Database    | Constructs a database and the required tables, before importing the data | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5684325a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== STARTING TO IMPORT DATA ========\n",
      "Inserting User Data...\n",
      "Inserting Building Data...\n"
     ]
    },
    {
     "ename": "UniqueViolation",
     "evalue": "duplicate key value violates unique constraint \"Building_buildingName_addressLine1_addressLine2_city_provin_key\"\nDETAIL:  Key (\"buildingName\", \"addressLine1\", \"addressLine2\", city, province, country, \"postalCode\")=(MC, 200 University Avenue West, MC, Waterloo, Ontario, Canada, N2L 3G1) already exists.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUniqueViolation\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m===== STARTING TO IMPORT DATA ========\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mimporter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimportData\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/Toy Dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcleanLevel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuildLevel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImportLevel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTuples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m========== IMPORT COMPLETE ===========\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\Computer\\Programs\\Python\\CS348\\cs348_project\\Tools\\DataImporter\\src\\DataImporter\\Importer.py:152\u001b[0m, in \u001b[0;36mImporter.importData\u001b[1;34m(self, dataFolder, buildLevel, cleanLevel)\u001b[0m\n\u001b[0;32m    149\u001b[0m bookingData, cancellationData \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minsertAndReplaceIds(userData, TableNames\u001b[38;5;241m.\u001b[39mUser\u001b[38;5;241m.\u001b[39mvalue, [bookingData, cancellationData], ColNames\u001b[38;5;241m.\u001b[39mUserId\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInserting Building Data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 152\u001b[0m roomData \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsertAndReplaceIds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuildingData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTableNames\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBuiding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mroomData\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mColNames\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBuildingId\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInserting Room Data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    155\u001b[0m bookingData \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minsertAndReplaceIds(roomData, TableNames\u001b[38;5;241m.\u001b[39mRoom\u001b[38;5;241m.\u001b[39mvalue, [bookingData], ColNames\u001b[38;5;241m.\u001b[39mRoomId\u001b[38;5;241m.\u001b[39mvalue)\n",
      "File \u001b[1;32me:\\Computer\\Programs\\Python\\CS348\\cs348_project\\Tools\\DataImporter\\src\\DataImporter\\Importer.py:77\u001b[0m, in \u001b[0;36mImporter.insertAndReplaceIds\u001b[1;34m(self, dataToInsert, insertTableName, dataNeedingReplace, idColName)\u001b[0m\n\u001b[0;32m     74\u001b[0m originalIds \u001b[38;5;241m=\u001b[39m dataToInsert[[idColName]]\n\u001b[0;32m     75\u001b[0m dataToInsert \u001b[38;5;241m=\u001b[39m dataToInsert\u001b[38;5;241m.\u001b[39mdrop(idColName, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m generatedIds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataToInsert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtableName\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minsertTableName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturnCols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43midColName\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m dataNeedingReplace):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32me:\\Computer\\Programs\\Python\\CS348\\cs348_project\\Tools\\PyUtils\\src\\PyUtils\\database\\DBTool.py:170\u001b[0m, in \u001b[0;36mDBTool.insert\u001b[1;34m(self, data, tableName, returnCols)\u001b[0m\n\u001b[0;32m    168\u001b[0m connData\u001b[38;5;241m.\u001b[39mputConn()\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (err):\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(returnVals, columns \u001b[38;5;241m=\u001b[39m returnCols)\n",
      "File \u001b[1;32me:\\Computer\\Programs\\Python\\CS348\\cs348_project\\Tools\\PyUtils\\src\\PyUtils\\database\\DBTool.py:111\u001b[0m, in \u001b[0;36mDBTool.executeSQL\u001b[1;34m(self, sql, vars, commit, closeConn, connData, raiseException)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[1;32m--> 111\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (commit):\n\u001b[0;32m    114\u001b[0m         conn\u001b[38;5;241m.\u001b[39mcommit()\n",
      "\u001b[1;31mUniqueViolation\u001b[0m: duplicate key value violates unique constraint \"Building_buildingName_addressLine1_addressLine2_city_provin_key\"\nDETAIL:  Key (\"buildingName\", \"addressLine1\", \"addressLine2\", city, province, country, \"postalCode\")=(MC, 200 University Avenue West, MC, Waterloo, Ontario, Canada, N2L 3G1) already exists.\n"
     ]
    }
   ],
   "source": [
    "print(\"===== STARTING TO IMPORT DATA ========\")\n",
    "\n",
    "importer.importData(r\"data/Toy Dataset\", cleanLevel = DI.ImportLevel.Database, buildLevel = DI.ImportLevel.Database)\n",
    "\n",
    "print(\"========== IMPORT COMPLETE ===========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c56724c",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Clearing all Data\n",
    "\n",
    "The following codeblock gives an example of clearing the data from all the tables\n",
    "\n",
    "<br>\n",
    "\n",
    "> ***‚ùó WARNING:*** <br>\n",
    ">\n",
    "> ONLY DO THIS IF YOU ARE ABSOLUTELY SURE OF WHAT YOU ARE DOING\n",
    "> \n",
    "\n",
    "<br>\n",
    "\n",
    "For the cleaning settings, please refer to the table at [Importing a Dataset](#importing-a-dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd142d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== STARTING TO DELETE DATA ========\n",
      "Deleting all tables...\n",
      "========= DELETION COMPLETE ==========\n"
     ]
    }
   ],
   "source": [
    "print(\"===== STARTING TO DELETE DATA ========\")\n",
    "\n",
    "importer.clean(cleanLevel = DI.ImportLevel.Tables)\n",
    "\n",
    "print(\"========= DELETION COMPLETE ==========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63b32e8",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Execute Custom SQL\n",
    "\n",
    "The following codeblock gives some example to execute some custom sql command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfa94d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Alice Margatroid',)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import psycopg2.sql\n",
    "\n",
    "\n",
    "selectNameSQL = psycopg2.sql.SQL(\"SELECT {nameCol} FROM {userTable} LIMIT 1\").format(\n",
    "    nameCol = psycopg2.sql.Identifier(\"name\"),\n",
    "    userTable = psycopg2.sql.Identifier(DI.TableNames.User.value)\n",
    ")\n",
    "\n",
    "conn, cursor, err = importer.executeSQL(selectNameSQL, closeConn = False)\n",
    "\n",
    "if (err is None):\n",
    "    print(cursor.fetchone())\n",
    "    conn.close()\n",
    "else:\n",
    "    conn.close()\n",
    "    raise err"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
